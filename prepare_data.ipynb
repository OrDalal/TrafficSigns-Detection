{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae66a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058eb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'E:\\\\Data\\\\DalalProject\\\\extract_zips\\\\camera00.tar'\n",
    "path_to_annotations = 'E:\\\\Data\\\\DalalProject\\\\extract_zips\\\\annotations.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d3ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_to_camera_tars = 'camera_zips'\n",
    "path_to_annotations_file = 'BelgiumTSD_annotations.zip'\n",
    "path_to_parsed_dataset = 'parsed_dataset'\n",
    "path_to_extract_data = 'extracted_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "146332db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perc = 0.8\n",
    "validation_perc = 0.1\n",
    "test_perc = 0.1\n",
    "\n",
    "classes_ofi = list(range(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181da9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_to_extract_data):\n",
    "    os.makedirs(path_to_extract_data)\n",
    "\n",
    "if not os.path.exists(path_to_parsed_dataset):\n",
    "    os.makedirs(path_to_parsed_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11bacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tar_file(path_to_tar_file, path_to_dst):\n",
    "    \n",
    "    if not os.path.exists(path_to_dst):\n",
    "        os.makedirs(path_to_dst)\n",
    "    \n",
    "    if tarfile.is_tarfile(path_to_tar_file):\n",
    "        with tarfile.open(path_to_tar_file) as f:\n",
    "            f.extractall(path=path_to_dst)  \n",
    "\n",
    "def extract_zip_file(path_to_zip_file, path_to_dst):\n",
    "    \n",
    "    if not os.path.exists(path_to_dst):\n",
    "        os.makedirs(path_to_dst)\n",
    "        \n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path_to_dst)\n",
    "\n",
    "extract_zip_file(path_to_annotations_file, os.path.join(path_to_extract_data, 'annotations'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b6f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_anot_file = os.path.join(path_to_extract_data, 'annotations', 'BelgiumTSD_annotations','BTSD_training_GT.txt')\n",
    "path_to_test_anot_file = os.path.join(path_to_extract_data, 'annotations', 'BelgiumTSD_annotations','BTSD_testing_GT.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2011aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_tars = list(os.walk(path_to_camera_tars))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0f3ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extractings  camera00.tar ..\n",
      "extractings  camera01.tar ..\n",
      "extractings  camera02.tar ..\n",
      "extractings  camera03.tar ..\n",
      "extractings  camera04.tar ..\n",
      "extractings  camera05.tar ..\n",
      "extractings  camera06.tar ..\n",
      "extractings  camera07.tar ..\n"
     ]
    }
   ],
   "source": [
    "for tar in camera_tars:\n",
    "    print('extractings ', tar, '..')\n",
    "    extract_tar_file(os.path.join(path_to_camera_tars, tar), os.path.join(path_to_extract_data, 'data'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3bb5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_annotation_file(path_to_annotation_file):\n",
    "    \n",
    "    with open(path_to_annotation_file, 'r') as f:\n",
    "        annotation_data = f.read()\n",
    "\n",
    "\n",
    "    lines = annotation_data.split('\\n')\n",
    "\n",
    "    file_names = []\n",
    "    file_coordinates = []\n",
    "    file_superclass = []\n",
    "    file_class = []\n",
    "    file_labels = []\n",
    "    \n",
    "    data_dict = {'file_names': [], \n",
    "                 'coordinates': [], \n",
    "                 'superclasses': [], \n",
    "                 'classes': [], \n",
    "                 'labels': []}\n",
    "    \n",
    "\n",
    "    superclasses_per_file = {}\n",
    "\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.split(';')\n",
    "\n",
    "        if len(parts) != 13:\n",
    "            #print('skipping line: ', line)\n",
    "            continue\n",
    "\n",
    "        path_to_image = parts[0]\n",
    "        coordinates = [float(i) for i in parts[1:5]]\n",
    "        superclass = int(parts[6])\n",
    "        tclass = int(parts[5])\n",
    "        label = parts[-2]\n",
    "\n",
    "        #print('path_to_image: ', path_to_image)\n",
    "        #print('\\tcoordinates: ', coordinates)\n",
    "        #print('\\tlabel: ', label)\n",
    "        #print('\\tsuperclass: ', superclass)\n",
    "\n",
    "        data_dict['file_names'].append(path_to_image)\n",
    "        data_dict['coordinates'].append(coordinates)\n",
    "        data_dict['labels'].append(label)\n",
    "        data_dict['superclasses'].append(superclass)\n",
    "        data_dict['classes'].append(tclass)\n",
    "\n",
    "        if path_to_image not in superclasses_per_file:\n",
    "            superclasses_per_file[path_to_image] = []\n",
    "\n",
    "        if superclass not in superclasses_per_file[path_to_image]:\n",
    "            superclasses_per_file[path_to_image].append(superclass)\n",
    "\n",
    "\n",
    "    all_train_files = []\n",
    "    all_validation_files = []\n",
    "    all_test_files = []\n",
    "\n",
    "    for class_ofi in classes_ofi:\n",
    "\n",
    "        rel_image_paths = []\n",
    "        for im_path in superclasses_per_file:\n",
    "            if class_ofi in superclasses_per_file[im_path]:\n",
    "                rel_image_paths.append(im_path)\n",
    "\n",
    "        random.shuffle(rel_image_paths)\n",
    "\n",
    "        amount_train = int(len(rel_image_paths) * train_perc)\n",
    "        amount_validation = int(len(rel_image_paths) * validation_perc)\n",
    "        amount_test = int(len(rel_image_paths) * test_perc)\n",
    "\n",
    "        train_files = rel_image_paths[:amount_train]\n",
    "        validation_files = rel_image_paths[amount_train: amount_train + amount_validation]\n",
    "        test_files = rel_image_paths[amount_train + amount_validation: ]\n",
    "\n",
    "\n",
    "        # This code makes sure that the same file type doesn't end up in more than one category.\n",
    "        for file in validation_files:\n",
    "            if file not in all_train_files and file not in all_test_files:\n",
    "                all_validation_files.append(file)\n",
    "\n",
    "\n",
    "        for file in test_files:\n",
    "            if file not in all_train_files and file not in all_validation_files:\n",
    "                all_test_files.append(file)\n",
    "\n",
    "\n",
    "        for file in train_files:\n",
    "            if file not in all_test_files and file not in all_validation_files:\n",
    "                all_train_files.append(file)\n",
    "    \n",
    "    return all_train_files, all_validation_files, all_test_files, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "736ab6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_train_files, train_all_validation_files, train_all_test_files, train_data_dict = extract_data_from_annotation_file(path_to_train_anot_file)\n",
    "test_all_train_files, test_all_validation_files, test_all_test_files, test_data_dict = extract_data_from_annotation_file(path_to_test_anot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87802ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_all_train_files = train_all_train_files + test_all_train_files\n",
    "global_all_validation_files = train_all_validation_files + test_all_validation_files\n",
    "global_all_test_files = train_all_test_files + test_all_test_files\n",
    "\n",
    "global_data_dict = {i: train_data_dict[i] + test_data_dict[i] for i in train_data_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aac3a10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_names', 'coordinates', 'superclasses', 'classes', 'labels'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d7f0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_data_dict = {\n",
    "                'file_names': [], \n",
    "                'coordinates': [], \n",
    "                'superclasses': [], \n",
    "                'classes': [], \n",
    "                'labels': []\n",
    "}\n",
    "final_validation_data_dict = {\n",
    "                'file_names': [], \n",
    "                'coordinates': [], \n",
    "                'superclasses': [], \n",
    "                'classes': [], \n",
    "                'labels': []\n",
    "}\n",
    "final_test_data_dict = {\n",
    "                'file_names': [], \n",
    "                'coordinates': [], \n",
    "                'superclasses': [], \n",
    "                'classes': [], \n",
    "                'labels': []\n",
    "}\n",
    "\n",
    "for src_d, dst_d in zip(\n",
    "    [global_all_train_files, global_all_validation_files, global_all_test_files], \n",
    "    [final_train_data_dict, final_validation_data_dict, final_test_data_dict]):\n",
    "    \n",
    "    \n",
    "    for file in src_d:\n",
    "        relevant_index = global_data_dict['file_names'].index(file)\n",
    "\n",
    "        dst_d['file_names'].append(global_data_dict['file_names'][relevant_index])\n",
    "        dst_d['coordinates'].append(global_data_dict['coordinates'][relevant_index])\n",
    "        dst_d['superclasses'].append(global_data_dict['superclasses'][relevant_index])\n",
    "        dst_d['classes'].append(global_data_dict['classes'][relevant_index])\n",
    "        dst_d['labels'].append(global_data_dict['labels'][relevant_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b7d2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.DataFrame(final_train_data_dict)\n",
    "train_dataframe.to_csv(os.path.join(path_to_parsed_dataset, 'train_annotation.csv'))\n",
    "\n",
    "validation_dataframe = pd.DataFrame(final_validation_data_dict)\n",
    "validation_dataframe.to_csv(os.path.join(path_to_parsed_dataset, 'validation_annotation.csv'))\n",
    "\n",
    "test_dataframe = pd.DataFrame(final_test_data_dict)\n",
    "test_dataframe.to_csv(os.path.join(path_to_parsed_dataset, 'test_annotation.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
